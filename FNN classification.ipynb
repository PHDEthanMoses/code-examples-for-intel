{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\JUPITER\\SHAD BASE\\DL 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Wine.txt', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input1</th>\n",
       "      <th>Input2</th>\n",
       "      <th>Input3</th>\n",
       "      <th>Input4</th>\n",
       "      <th>Input5</th>\n",
       "      <th>Input6</th>\n",
       "      <th>Input7</th>\n",
       "      <th>Input8</th>\n",
       "      <th>Input9</th>\n",
       "      <th>Input10</th>\n",
       "      <th>Input11</th>\n",
       "      <th>Input12</th>\n",
       "      <th>Input13</th>\n",
       "      <th>Desired1(3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.12</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.32</td>\n",
       "      <td>16.8</td>\n",
       "      <td>95</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.2</td>\n",
       "      <td>112</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.83</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.62</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.19</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>108</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.86</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>126</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.65</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.71</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>102</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.52</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.71</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.8</td>\n",
       "      <td>95</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.82</td>\n",
       "      <td>845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.62</td>\n",
       "      <td>16.1</td>\n",
       "      <td>93</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>94</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>19.4</td>\n",
       "      <td>107</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>11.45</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.39</td>\n",
       "      <td>625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>11.56</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.23</td>\n",
       "      <td>28.5</td>\n",
       "      <td>119</td>\n",
       "      <td>3.18</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.87</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.69</td>\n",
       "      <td>465</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12.42</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.73</td>\n",
       "      <td>26.5</td>\n",
       "      <td>102</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.12</td>\n",
       "      <td>365</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>13.05</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2.13</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.10</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>11.87</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.39</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.64</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12.07</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>85</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.28</td>\n",
       "      <td>378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12.43</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.84</td>\n",
       "      <td>352</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>11.79</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.78</td>\n",
       "      <td>28.5</td>\n",
       "      <td>92</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.44</td>\n",
       "      <td>466</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>88</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.78</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>12.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.38</td>\n",
       "      <td>22.0</td>\n",
       "      <td>80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.57</td>\n",
       "      <td>580</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.29</td>\n",
       "      <td>630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12.88</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.40</td>\n",
       "      <td>20.0</td>\n",
       "      <td>104</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.42</td>\n",
       "      <td>530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12.81</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.40</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.36</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12.70</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.29</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12.51</td>\n",
       "      <td>1.24</td>\n",
       "      <td>2.25</td>\n",
       "      <td>17.5</td>\n",
       "      <td>85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.51</td>\n",
       "      <td>650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12.60</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.5</td>\n",
       "      <td>94</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.58</td>\n",
       "      <td>695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12.25</td>\n",
       "      <td>4.72</td>\n",
       "      <td>2.54</td>\n",
       "      <td>21.0</td>\n",
       "      <td>89</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.27</td>\n",
       "      <td>720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "      <td>515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>13.49</td>\n",
       "      <td>3.59</td>\n",
       "      <td>2.19</td>\n",
       "      <td>19.5</td>\n",
       "      <td>88</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.82</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>12.84</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.61</td>\n",
       "      <td>24.0</td>\n",
       "      <td>101</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.15</td>\n",
       "      <td>590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12.93</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.31</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>13.36</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.47</td>\n",
       "      <td>780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>13.52</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.72</td>\n",
       "      <td>23.5</td>\n",
       "      <td>97</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.06</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>13.62</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.05</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>12.25</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.5</td>\n",
       "      <td>112</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.00</td>\n",
       "      <td>855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>13.16</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2.15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.68</td>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>13.88</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.33</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>12.87</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.48</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.86</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>13.32</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.5</td>\n",
       "      <td>92</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>113</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.33</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input1  Input2  Input3  Input4  Input5  Input6  Input7  Input8  Input9  \\\n",
       "0     14.23    1.71    2.43    15.6     127    2.80    3.06    0.28    2.29   \n",
       "1     13.20    1.78    2.14    11.2     100    2.65    2.76    0.26    1.28   \n",
       "2     13.16    2.36    2.67    18.6     101    2.80    3.24    0.30    2.81   \n",
       "3     14.37    1.95    2.50    16.8     113    3.85    3.49    0.24    2.18   \n",
       "4     13.24    2.59    2.87    21.0     118    2.80    2.69    0.39    1.82   \n",
       "5     14.20    1.76    2.45    15.2     112    3.27    3.39    0.34    1.97   \n",
       "6     14.39    1.87    2.45    14.6      96    2.50    2.52    0.30    1.98   \n",
       "7     14.06    2.15    2.61    17.6     121    2.60    2.51    0.31    1.25   \n",
       "8     14.83    1.64    2.17    14.0      97    2.80    2.98    0.29    1.98   \n",
       "9     13.86    1.35    2.27    16.0      98    2.98    3.15    0.22    1.85   \n",
       "10    14.10    2.16    2.30    18.0     105    2.95    3.32    0.22    2.38   \n",
       "11    14.12    1.48    2.32    16.8      95    2.20    2.43    0.26    1.57   \n",
       "12    13.75    1.73    2.41    16.0      89    2.60    2.76    0.29    1.81   \n",
       "13    14.75    1.73    2.39    11.4      91    3.10    3.69    0.43    2.81   \n",
       "14    14.38    1.87    2.38    12.0     102    3.30    3.64    0.29    2.96   \n",
       "15    13.63    1.81    2.70    17.2     112    2.85    2.91    0.30    1.46   \n",
       "16    14.30    1.92    2.72    20.0     120    2.80    3.14    0.33    1.97   \n",
       "17    13.83    1.57    2.62    20.0     115    2.95    3.40    0.40    1.72   \n",
       "18    14.19    1.59    2.48    16.5     108    3.30    3.93    0.32    1.86   \n",
       "19    13.64    3.10    2.56    15.2     116    2.70    3.03    0.17    1.66   \n",
       "20    14.06    1.63    2.28    16.0     126    3.00    3.17    0.24    2.10   \n",
       "21    12.93    3.80    2.65    18.6     102    2.41    2.41    0.25    1.98   \n",
       "22    13.71    1.86    2.36    16.6     101    2.61    2.88    0.27    1.69   \n",
       "23    12.85    1.60    2.52    17.8      95    2.48    2.37    0.26    1.46   \n",
       "24    13.50    1.81    2.61    20.0      96    2.53    2.61    0.28    1.66   \n",
       "25    13.05    2.05    3.22    25.0     124    2.63    2.68    0.47    1.92   \n",
       "26    13.39    1.77    2.62    16.1      93    2.85    2.94    0.34    1.45   \n",
       "27    13.30    1.72    2.14    17.0      94    2.40    2.19    0.27    1.35   \n",
       "28    13.87    1.90    2.80    19.4     107    2.95    2.97    0.37    1.76   \n",
       "29    14.02    1.68    2.21    16.0      96    2.65    2.33    0.26    1.98   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "120   11.45    2.40    2.42    20.0      96    2.90    2.79    0.32    1.83   \n",
       "121   11.56    2.05    3.23    28.5     119    3.18    5.08    0.47    1.87   \n",
       "122   12.42    4.43    2.73    26.5     102    2.20    2.13    0.43    1.71   \n",
       "123   13.05    5.80    2.13    21.5      86    2.62    2.65    0.30    2.01   \n",
       "124   11.87    4.31    2.39    21.0      82    2.86    3.03    0.21    2.91   \n",
       "125   12.07    2.16    2.17    21.0      85    2.60    2.65    0.37    1.35   \n",
       "126   12.43    1.53    2.29    21.5      86    2.74    3.15    0.39    1.77   \n",
       "127   11.79    2.13    2.78    28.5      92    2.13    2.24    0.58    1.76   \n",
       "128   12.37    1.63    2.30    24.5      88    2.22    2.45    0.40    1.90   \n",
       "129   12.04    4.30    2.38    22.0      80    2.10    1.75    0.42    1.35   \n",
       "130   12.86    1.35    2.32    18.0     122    1.51    1.25    0.21    0.94   \n",
       "131   12.88    2.99    2.40    20.0     104    1.30    1.22    0.24    0.83   \n",
       "132   12.81    2.31    2.40    24.0      98    1.15    1.09    0.27    0.83   \n",
       "133   12.70    3.55    2.36    21.5     106    1.70    1.20    0.17    0.84   \n",
       "134   12.51    1.24    2.25    17.5      85    2.00    0.58    0.60    1.25   \n",
       "135   12.60    2.46    2.20    18.5      94    1.62    0.66    0.63    0.94   \n",
       "136   12.25    4.72    2.54    21.0      89    1.38    0.47    0.53    0.80   \n",
       "137   12.53    5.51    2.64    25.0      96    1.79    0.60    0.63    1.10   \n",
       "138   13.49    3.59    2.19    19.5      88    1.62    0.48    0.58    0.88   \n",
       "139   12.84    2.96    2.61    24.0     101    2.32    0.60    0.53    0.81   \n",
       "140   12.93    2.81    2.70    21.0      96    1.54    0.50    0.53    0.75   \n",
       "141   13.36    2.56    2.35    20.0      89    1.40    0.50    0.37    0.64   \n",
       "142   13.52    3.17    2.72    23.5      97    1.55    0.52    0.50    0.55   \n",
       "143   13.62    4.95    2.35    20.0      92    2.00    0.80    0.47    1.02   \n",
       "144   12.25    3.88    2.20    18.5     112    1.38    0.78    0.29    1.14   \n",
       "145   13.16    3.57    2.15    21.0     102    1.50    0.55    0.43    1.30   \n",
       "146   13.88    5.04    2.23    20.0      80    0.98    0.34    0.40    0.68   \n",
       "147   12.87    4.61    2.48    21.5      86    1.70    0.65    0.47    0.86   \n",
       "148   13.32    3.24    2.38    21.5      92    1.93    0.76    0.45    1.25   \n",
       "149   13.08    3.90    2.36    21.5     113    1.41    1.39    0.34    1.14   \n",
       "\n",
       "     Input10  Input11  Input12  Input13  Desired1(3)  \n",
       "0       5.64     1.04     3.92     1065            0  \n",
       "1       4.38     1.05     3.40     1050            0  \n",
       "2       5.68     1.03     3.17     1185            0  \n",
       "3       7.80     0.86     3.45     1480            0  \n",
       "4       4.32     1.04     2.93      735            0  \n",
       "5       6.75     1.05     2.85     1450            0  \n",
       "6       5.25     1.02     3.58     1290            0  \n",
       "7       5.05     1.06     3.58     1295            0  \n",
       "8       5.20     1.08     2.85     1045            0  \n",
       "9       7.22     1.01     3.55     1045            0  \n",
       "10      5.75     1.25     3.17     1510            0  \n",
       "11      5.00     1.17     2.82     1280            0  \n",
       "12      5.60     1.15     2.90     1320            0  \n",
       "13      5.40     1.25     2.73     1150            0  \n",
       "14      7.50     1.20     3.00     1547            0  \n",
       "15      7.30     1.28     2.88     1310            0  \n",
       "16      6.20     1.07     2.65     1280            0  \n",
       "17      6.60     1.13     2.57     1130            0  \n",
       "18      8.70     1.23     2.82     1680            0  \n",
       "19      5.10     0.96     3.36      845            0  \n",
       "20      5.65     1.09     3.71      780            0  \n",
       "21      4.50     1.03     3.52      770            0  \n",
       "22      3.80     1.11     4.00     1035            0  \n",
       "23      3.93     1.09     3.63     1015            0  \n",
       "24      3.52     1.12     3.82      845            0  \n",
       "25      3.58     1.13     3.20      830            0  \n",
       "26      4.80     0.92     3.22     1195            0  \n",
       "27      3.95     1.02     2.77     1285            0  \n",
       "28      4.50     1.25     3.40      915            0  \n",
       "29      4.70     1.04     3.59     1035            0  \n",
       "..       ...      ...      ...      ...          ...  \n",
       "120     3.25     0.80     3.39      625            2  \n",
       "121     6.00     0.93     3.69      465            2  \n",
       "122     2.08     0.92     3.12      365            2  \n",
       "123     2.60     0.73     3.10      380            2  \n",
       "124     2.80     0.75     3.64      380            2  \n",
       "125     2.76     0.86     3.28      378            2  \n",
       "126     3.94     0.69     2.84      352            2  \n",
       "127     3.00     0.97     2.44      466            2  \n",
       "128     2.12     0.89     2.78      342            2  \n",
       "129     2.60     0.79     2.57      580            2  \n",
       "130     4.10     0.76     1.29      630            1  \n",
       "131     5.40     0.74     1.42      530            1  \n",
       "132     5.70     0.66     1.36      560            1  \n",
       "133     5.00     0.78     1.29      600            1  \n",
       "134     5.45     0.75     1.51      650            1  \n",
       "135     7.10     0.73     1.58      695            1  \n",
       "136     3.85     0.75     1.27      720            1  \n",
       "137     5.00     0.82     1.69      515            1  \n",
       "138     5.70     0.81     1.82      580            1  \n",
       "139     4.92     0.89     2.15      590            1  \n",
       "140     4.60     0.77     2.31      600            1  \n",
       "141     5.60     0.70     2.47      780            1  \n",
       "142     4.35     0.89     2.06      520            1  \n",
       "143     4.40     0.91     2.05      550            1  \n",
       "144     8.21     0.65     2.00      855            1  \n",
       "145     4.00     0.60     1.68      830            1  \n",
       "146     4.90     0.58     1.33      415            1  \n",
       "147     7.65     0.54     1.86      625            1  \n",
       "148     8.42     0.55     1.62      650            1  \n",
       "149     9.40     0.57     1.33      550            1  \n",
       "\n",
       "[150 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.398876\n",
       "0    0.331461\n",
       "1    0.269663\n",
       "Name: Desired1(3), dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Desired1(3)'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['Desired1(3)']\n",
    "X=df.drop('Desired1(3)', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=12345,\n",
    "                                                    # доля объёма тестового множества\n",
    "                                                    test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_bin = np_utils.to_categorical(Y_train)\n",
    "\n",
    "Y_test_bin = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_bin[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "119/119 [==============================] - 0s 496us/step - loss: 1.3590 - accuracy: 0.3866\n",
      "Epoch 2/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0999 - accuracy: 0.2689\n",
      "Epoch 3/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.1000 - accuracy: 0.3193\n",
      "Epoch 4/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0994 - accuracy: 0.3193\n",
      "Epoch 5/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0986 - accuracy: 0.3193\n",
      "Epoch 6/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0981 - accuracy: 0.3697\n",
      "Epoch 7/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0974 - accuracy: 0.4118\n",
      "Epoch 8/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0966 - accuracy: 0.4118\n",
      "Epoch 9/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0959 - accuracy: 0.4118\n",
      "Epoch 10/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0954 - accuracy: 0.4118\n",
      "Epoch 11/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0949 - accuracy: 0.4118\n",
      "Epoch 12/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0941 - accuracy: 0.4118\n",
      "Epoch 13/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0935 - accuracy: 0.4118\n",
      "Epoch 14/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0934 - accuracy: 0.4118\n",
      "Epoch 15/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0925 - accuracy: 0.4118\n",
      "Epoch 16/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0921 - accuracy: 0.4118\n",
      "Epoch 17/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0916 - accuracy: 0.4118\n",
      "Epoch 18/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0912 - accuracy: 0.4118\n",
      "Epoch 19/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0909 - accuracy: 0.4118\n",
      "Epoch 20/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0904 - accuracy: 0.4118\n",
      "Epoch 21/300\n",
      "119/119 [==============================] - 0s 84us/step - loss: 1.0900 - accuracy: 0.4118\n",
      "Epoch 22/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0898 - accuracy: 0.4118\n",
      "Epoch 23/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0894 - accuracy: 0.4118\n",
      "Epoch 24/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0890 - accuracy: 0.4118\n",
      "Epoch 25/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0887 - accuracy: 0.4118\n",
      "Epoch 26/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0884 - accuracy: 0.4118\n",
      "Epoch 27/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0881 - accuracy: 0.4118\n",
      "Epoch 28/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0878 - accuracy: 0.4118\n",
      "Epoch 29/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0876 - accuracy: 0.4118\n",
      "Epoch 30/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "Epoch 31/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 32/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0870 - accuracy: 0.4118\n",
      "Epoch 33/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 34/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 35/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 36/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 37/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 38/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 39/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 40/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 41/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 42/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 43/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 44/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 45/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 46/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 47/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 48/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 49/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 50/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 51/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 52/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 53/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 54/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 55/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 56/300\n",
      "119/119 [==============================] - 0s 84us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 57/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 58/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 59/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 60/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 61/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 62/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 63/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 64/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 65/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 66/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 67/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 68/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 69/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 70/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 71/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 72/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 73/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0835 - accuracy: 0.4118\n",
      "Epoch 74/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0835 - accuracy: 0.4118\n",
      "Epoch 75/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0835 - accuracy: 0.4118\n",
      "Epoch 76/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0835 - accuracy: 0.4118\n",
      "Epoch 77/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0834 - accuracy: 0.4118\n",
      "Epoch 78/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0835 - accuracy: 0.4118\n",
      "Epoch 79/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0834 - accuracy: 0.4118\n",
      "Epoch 80/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0834 - accuracy: 0.4118\n",
      "Epoch 81/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0834 - accuracy: 0.4118\n",
      "Epoch 82/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0834 - accuracy: 0.4118\n",
      "Epoch 83/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0835 - accuracy: 0.4118\n",
      "Epoch 84/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 85/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 86/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 87/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 88/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 89/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0834 - accuracy: 0.4118\n",
      "Epoch 90/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 91/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0834 - accuracy: 0.4118\n",
      "Epoch 92/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 93/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 94/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 95/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 96/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 97/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 98/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 99/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 100/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 101/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 102/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 103/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 104/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 105/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 106/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 107/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 108/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 109/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 110/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 111/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 112/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 113/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 114/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 115/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 116/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 117/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 118/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 119/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 120/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 121/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 122/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 123/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0833 - accuracy: 0.4118\n",
      "Epoch 124/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 125/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 126/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 127/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 128/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 129/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 130/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 131/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 132/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 133/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 134/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 135/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 136/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 137/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 138/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 139/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 140/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 141/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 142/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 143/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 144/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 145/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 146/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 147/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 148/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 149/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 150/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 151/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 152/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 153/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 154/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 155/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 156/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 157/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 158/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 159/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 160/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 161/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 162/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 163/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 164/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 165/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 166/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 167/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 168/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 169/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 170/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 171/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 172/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 173/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 174/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 175/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 176/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 177/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 178/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 179/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 180/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 181/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 182/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 183/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 184/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 185/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 186/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 187/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 188/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 189/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 190/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 191/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 192/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 193/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 194/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 195/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 196/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 197/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 198/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 199/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 200/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 201/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 202/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 203/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 204/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 205/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 206/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 207/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 208/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 209/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 210/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 211/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 212/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 213/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 214/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 215/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 216/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 217/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 218/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 219/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 220/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 221/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 222/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 223/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 224/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 225/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 226/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 227/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 228/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 229/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 230/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 231/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 232/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 233/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 234/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 235/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 236/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 237/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 238/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 239/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 240/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 241/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 242/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 243/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 244/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 245/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 246/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 247/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 248/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 249/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 250/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 251/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 252/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 253/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 254/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 255/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 256/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 257/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 258/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 259/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 260/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 261/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 262/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 263/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 264/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 265/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 266/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 267/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 268/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 269/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 270/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 271/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 272/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 273/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 274/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0832 - accuracy: 0.4118\n",
      "Epoch 275/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 276/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 277/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 278/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 279/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 280/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 281/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 282/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 283/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 284/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 285/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 286/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 287/300\n",
      "119/119 [==============================] - 0s 76us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 288/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 289/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 290/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 291/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 292/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 293/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 294/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 295/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 296/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 297/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 298/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 299/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0831 - accuracy: 0.4118\n",
      "Epoch 300/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0831 - accuracy: 0.4118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x10e84da0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a model\n",
    "model = Sequential()\n",
    "model.add(Dense(9, input_dim=13, activation='relu'))\n",
    "model.add(Dense(10, activation='relu', ))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compiling model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Training a model\n",
    "model.fit(X_train, Y_train_bin, epochs=300, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 203us/step\n",
      "\n",
      "Accuracy: 37.29%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test_bin)\n",
    "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict(X_test)\n",
    "# round predictions\n",
    "# rounded = [round(x[0]) for x in predictions]\n",
    "# print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3194572  0.26888973 0.41165313]\n",
      " [0.3194572  0.26888973 0.41165313]\n",
      " [0.3194572  0.26888973 0.41165313]\n",
      " [0.3194572  0.26888973 0.41165313]\n",
      " [0.3194572  0.26888973 0.41165313]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "119/119 [==============================] - 0s 262us/step - loss: 1.2225 - accuracy: 0.3950\n",
      "Epoch 2/300\n",
      "119/119 [==============================] - 0s 131us/step - loss: 1.0911 - accuracy: 0.4118\n",
      "Epoch 3/300\n",
      "119/119 [==============================] - 0s 0us/step - loss: 1.0879 - accuracy: 0.4118\n",
      "Epoch 4/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 5/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 6/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 7/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 8/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 9/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 10/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 11/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 12/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 13/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 14/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 15/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 16/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 17/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 18/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 19/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 20/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 21/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 22/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 23/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 24/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 25/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 26/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 27/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 28/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 29/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 30/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 31/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 32/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 33/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 34/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 35/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 36/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 37/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 38/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 39/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 40/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 41/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 42/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 43/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 44/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 45/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 46/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 47/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 48/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 49/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 50/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 51/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 52/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 53/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 54/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 55/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 56/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 57/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 58/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 59/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 60/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 61/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 62/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 63/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 64/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 65/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 66/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 67/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 68/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 69/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 70/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 71/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 72/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 73/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 74/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 75/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 76/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 77/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 78/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 79/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 80/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 81/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 82/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 83/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 84/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 85/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 86/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 87/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 88/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 89/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 90/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 91/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 92/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 93/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 94/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 95/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 96/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 97/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 98/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 99/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 100/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 101/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 102/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 103/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 104/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 105/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 106/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 107/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 108/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 109/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 110/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 111/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 112/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 113/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 114/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 115/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 116/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 117/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 118/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 119/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 120/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 121/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 122/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 123/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 124/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 125/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 126/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "Epoch 127/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 128/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 129/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 130/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 131/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 132/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 133/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 134/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 135/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 136/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 137/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 138/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 139/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 140/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 141/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 142/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 143/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 144/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 145/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 146/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 147/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 148/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 149/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 150/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 151/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0870 - accuracy: 0.4118\n",
      "Epoch 152/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 153/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 154/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 155/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 156/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 157/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 158/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 159/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 160/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 161/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0880 - accuracy: 0.4118\n",
      "Epoch 162/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 163/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 164/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 165/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 166/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 167/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 168/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 169/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 170/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 171/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 172/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 173/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 174/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 175/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 176/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 177/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 178/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 179/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 180/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 181/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 182/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 183/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 184/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 185/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 186/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 187/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 188/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 189/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 190/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 191/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 192/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 193/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 194/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 195/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 196/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 197/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 198/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 199/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 200/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 201/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 202/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 203/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0869 - accuracy: 0.4118\n",
      "Epoch 204/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 205/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 206/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 207/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 208/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 209/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 210/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 211/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 212/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 213/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0901 - accuracy: 0.4118\n",
      "Epoch 214/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 215/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 216/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 217/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 218/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 219/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 220/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 221/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 222/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 223/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 224/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 225/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 226/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 227/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 228/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 229/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 230/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 231/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 232/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 233/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 234/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 235/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 236/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 237/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 238/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 239/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0892 - accuracy: 0.4118\n",
      "Epoch 240/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 241/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 242/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 243/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 244/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "Epoch 245/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 246/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 247/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 248/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 249/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0869 - accuracy: 0.4118\n",
      "Epoch 250/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 251/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 252/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 253/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 254/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 255/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 256/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 257/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 258/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 259/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 260/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 261/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 262/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 263/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 264/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 265/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 266/300\n",
      "119/119 [==============================] - 0s 67us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 267/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 268/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 269/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 270/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 271/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 272/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 273/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 274/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 275/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 276/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 277/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0875 - accuracy: 0.4118\n",
      "Epoch 278/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 279/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 280/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 281/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 282/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 283/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 284/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 285/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 286/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 287/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 288/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 289/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 290/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 291/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 292/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 293/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 294/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 295/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 296/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "Epoch 297/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 298/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 299/300\n",
      "119/119 [==============================] - 0s 59us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 300/300\n",
      "119/119 [==============================] - 0s 50us/step - loss: 1.0841 - accuracy: 0.4118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1416f390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_2 = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=12345)\n",
    "init_3 = initializers.Constant(value = 1e-3)\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(9, input_dim=13, activation='relu', kernel_initializer=init_2, bias_initializer=init_3))\n",
    "model3.add(Dense(10, activation='relu', kernel_initializer=init_2, bias_initializer=init_3 ))\n",
    "model3.add(Dense(3, activation='softmax', kernel_initializer=init_2, bias_initializer=init_3))\n",
    "\n",
    "\n",
    "#  kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "\n",
    "\n",
    "# Compiling model\n",
    "\n",
    "sgd2 = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=sgd2, metrics=['accuracy'])\n",
    "\n",
    "#  model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Training a model\n",
    "model3.fit(X_train, Y_train_bin, epochs=300, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 220us/step\n",
      "\n",
      "Accuracy: 37.29%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model3.evaluate(X_test, Y_test_bin)\n",
    "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions_3 = model3.predict(X_test)\n",
    "# round predictions\n",
    "# rounded = [round(x[0]) for x in predictions]\n",
    "# print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32018209 0.26866364 0.41115433]\n",
      " [0.32018209 0.26866364 0.41115433]\n",
      " [0.32018209 0.26866364 0.41115433]\n",
      " [0.32018209 0.26866364 0.41115433]\n",
      " [0.32018209 0.26866364 0.41115433]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_3[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
